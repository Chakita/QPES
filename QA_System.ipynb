{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Aakansha281/Information-Retrieval-based-Question-Answering-System/blob/master/QA_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "usduAw6FdJxE"
   },
   "source": [
    "**Closed Domain Question Answering system:**\n",
    "Uses a reference text to answer the question posed by the user in natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5ArZ7hoVk0-Z",
    "outputId": "8d855529-f2ea-4c92-a26f-24ddb362e3a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aditeya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Aditeya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the required packages\n",
    "import nltk\n",
    "#nltk.download('all')\n",
    "import re\n",
    "import string\n",
    "import gensim \n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from nltk import pos_tag,word_tokenize,ne_chunk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pandas import DataFrame\n",
    "\n",
    "from nltk.corpus import wordnet,stopwords\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eX8Y2H02dwAC"
   },
   "source": [
    "**Uploading the Reference Article**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "N3kTgL0Qk6tn",
    "outputId": "7fc3c4f1-7baa-4680-dbb7-dc003583ec1b"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#uploaded=files.upload()\n",
    "sample = open(\"COVID19_wikipedia article.txt\", \"r\") \n",
    "\n",
    "s = sample.read() \n",
    "s=s.replace(\"COVID 19\",\"coronavirus\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCo5W9nCd9Pl"
   },
   "source": [
    "**Text Preprocessing Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNjJvOtSk7bs"
   },
   "outputs": [],
   "source": [
    "def stem_sentence(sentence):\n",
    "  words=word_tokenize(sentence)\n",
    "  #lemmatizer = WordNetLemmatizer()\n",
    "  \n",
    "  \n",
    "  stemmer = SnowballStemmer(\"english\")\n",
    "  new_words=[]\n",
    "  for i in words:\n",
    "    new_words.append(stemmer.stem(i))\n",
    "    new_words.append(\" \")\n",
    "  return \"\".join(new_words)  \n",
    "  \n",
    "\n",
    "\n",
    "def clean_sentence(sentence, stopwords=True):\n",
    "    \n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if stopwords:\n",
    "         sentence = remove_stopwords(sentence)\n",
    "    \n",
    "   \n",
    "    \n",
    "    return sentence\n",
    "def get_cleaned_sentences(sents,stopwords=True):    \n",
    "    \n",
    "    cleaned_sentences=[]\n",
    "\n",
    "    for i in sents:\n",
    "        \n",
    "        cleaning=clean_sentence(i,stopwords)\n",
    "        cleaned=stem_sentence(cleaning)\n",
    "        cleaned_sentences.append(cleaned)\n",
    "    return cleaned_sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UKROOQz6edpa"
   },
   "source": [
    "**create_document_term_matrix: Function to create TF - IDF Matrix**\n",
    "\n",
    "\n",
    "**calculate_cosine_similarity: Function to return the top 3 sentences based on cosine similarity between TF-IDF scores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DrfY_71UeRcg"
   },
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFQbswivlAlp"
   },
   "outputs": [],
   "source": [
    "def create_document_term_matrix(sen,vectorizer):\n",
    "  doc_term_matrix=vectorizer.fit_transform(sen)\n",
    "  return DataFrame(doc_term_matrix.toarray(), columns=vectorizer.get_feature_names())\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kPdXonU2e9Ew"
   },
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "28eA0yL0lFL7"
   },
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(df_list,sentences,question):\n",
    "  a=[]\n",
    "  for i in range(len(df_list)-1):\n",
    "    sim=1 - spatial.distance.cosine(df_list[i], question)\n",
    "    t=(sim,sentences[i])\n",
    "    a.append(t)\n",
    "  a.sort(reverse=True)\n",
    "  n=[]\n",
    "  for i in range(3):\n",
    "    n.append(a[i][1])\n",
    "    #print(\"*\",n[i])\n",
    "   \n",
    "    \n",
    "  return n  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fA81IVTvdGz6"
   },
   "source": [
    "**Function to classify questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tRYoXgLYlNSD"
   },
   "outputs": [],
   "source": [
    "def questiontype( question):\n",
    "        questiontags = ['WP','WDT','WP$','WRB']\n",
    "        question_POS = pos_tag(word_tokenize(question.lower()))\n",
    "        \n",
    "        question_Tags=[]\n",
    "        for token in question_POS:\n",
    "            if token[1] in questiontags:\n",
    "              question_Tags.append(token)\n",
    "                \n",
    "                \n",
    "        if len(question_Tags)==1 and question_Tags[0][0]!= 'what' :\n",
    "          return True\n",
    "        else:\n",
    "          return False  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vKwWilpbfigw"
   },
   "source": [
    "**Function to find the most relevant sentence using n-gram similarity **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Cli_jJ0lONW"
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "def n_gram_similarity(question,n):\n",
    "  q=list(ngrams(word_tokenize(question.lower()),1))\n",
    "  a=0\n",
    "  b=0\n",
    "  c=0\n",
    "  t=[]\n",
    "  for i in q:\n",
    "    if i in list(ngrams(word_tokenize(n[0].lower()),1)):\n",
    "      a=a+1\n",
    "  for i in q:\n",
    "    if i in list(ngrams(word_tokenize(n[1].lower()),1)):\n",
    "      b=b+1\n",
    "  for i in q:\n",
    "    if i in list(ngrams(word_tokenize(n[2].lower()),1)):\n",
    "      c=c+1        \n",
    "  d=max(a,b,c)\n",
    "  if a == d:\n",
    "    t.append(n[0])\n",
    "  if b == d:\n",
    "    t.append(n[1]) \n",
    "  if c ==d:\n",
    "    t.append(n[2])\n",
    "  print()  \n",
    "  #print(\"Selected Sentence:\",t[0])  \n",
    "  return t  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vaFGtZwff2Cr"
   },
   "source": [
    "**answertype:**Determines the type of entity that has to be returned, performs entity ranking if multiple entities a present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xKBe8u5slTdA"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def answertype(question):\n",
    "\n",
    "  if (questiontype(question)):\n",
    "    t='DESCRIPTIVE'\n",
    "    flag=0\n",
    "    word=word_tokenize(question.lower())\n",
    "  \n",
    "    if 'who' in word:\n",
    "      t='PERSON'\n",
    "    elif 'where' in word:\n",
    "      t='GPE'\n",
    "    elif 'how' in word and 'many' in word and  'age' in word or 'duration' in word or 'long' in word or 'days'in word or 'years' in word or'months' in word:\n",
    "      t='DATE' \n",
    "    elif 'how' in word and 'many' in word :\n",
    "       t = 'CARDINAL'  \n",
    "    elif 'when' in word  or 'age' in word or 'period' in word or 'duration' in word  or 'old' in word or 'long' in word:\n",
    "      t='DATE'\n",
    "    elif 'how' in word  and 'long' in word or 'often' or 'age' in word or 'years' in word:\n",
    "      t='DATE' \n",
    "    elif 'what' in word and 'time' in word or 'duration' in word or 'period' in  'word'  :\n",
    "      t='DATE' \n",
    "    i=len(df_list)-1  \n",
    "    n=calculate_cosine_similarity(df_list, sentences,df_list[i])\n",
    "    n=n_gram_similarity(question,n)\n",
    "    #print(\"Most relevant sentence\", n[0])\n",
    "    #print(\"ANSWER TYPE:\",t)\n",
    "    key = n[0]\n",
    "    spdoc = nlp(key)\n",
    "    entity_type=[]\n",
    "    for ent in spdoc.ents:\n",
    "       if ent.label_ == t:\n",
    "          entity_type.append(ent.text)\n",
    "    if len(entity_type) == 1:\n",
    "      #print(\"ANSWER TYPE:\", t)\n",
    "      print(\"ANSWER:\", entity_type[0])  \n",
    "    if len(entity_type) == 0:\n",
    "      #print(\"ANSWER TYPE:\", t) \n",
    "      print(n[0])\n",
    "    if len(entity_type) > 1:\n",
    "      #print(\"Answer Type:\",t)  \n",
    "      key_question = question\n",
    "      q=[]\n",
    "      spdoc = nlp(key_question)\n",
    "      for ent in spdoc:\n",
    "        if ent.pos_ == 'NOUN' or ent.pos_ =='ADJ' :\n",
    "          q.append(ent.text)\n",
    "  \n",
    "      key_answer = n[0]\n",
    "      a = []\n",
    "      spd = nlp(key)\n",
    "      for ent in spd:\n",
    "        if ent.pos_ == 'NOUN'or ent.pos_ =='ADJ' :\n",
    "          a.append(ent.text)\n",
    "  #s=[sentence.index(i) for i in t]\n",
    "      s=[]\n",
    "      w=[]\n",
    "      for i in entity_type:\n",
    "       s.append(n[0].index(i))\n",
    "      for i in range(len(s)):\n",
    "        w.append(0)\n",
    "\n",
    "    \n",
    "      for i in q:\n",
    "        try:\n",
    "           factor= n[0].index(i)\n",
    "           for j in range(len(s)):\n",
    "              w[j]=w[j]+(abs(s[j]-factor))\n",
    "        except:\n",
    "           continue    \n",
    "      m=min(w)\n",
    "      u=[]\n",
    "      for i in range(len(s)):\n",
    "        if w[i] == m:\n",
    "           #print(entity_type[i])\n",
    "           u.append(entity_type[i])\n",
    "      print(\"ANSWER:\",u[0])     \n",
    "      \n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  else:\n",
    "    t='DESCRIPTIVE'\n",
    "    #print(\"ANSWER TYPE:\",t)\n",
    "    i=len(df_list)-1  \n",
    "    n=calculate_cosine_similarity(df_list, sentences,df_list[i])\n",
    "    #n = n_gram_similarity(question, n)\n",
    "    for j in n:\n",
    "         print(j) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "m1r9nOcqlezX",
    "outputId": "d93647b9-355a-43cb-deb6-ac489a3530e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: What is PES\n",
      "People's Education Society University Ring Road Campus (PESU RR or just PESU), formerly PES Institute of Technology (PESIT), is one of three private universities under the name PES University in Bengaluru, India.\n",
      "Crucible Of Research and Innovation (CORI) is a multi-disciplinary research center at PES University.\n",
      "PES currently manages over 45 educational programs in Karnataka and neighboring Andhra Pradesh, with a total of over 15000 students.\n",
      "\n",
      "QUESTION: Where is PES located\n",
      "\n",
      "ANSWER: Bengaluru\n",
      "\n",
      "QUESTION: How to get admitted in PES\n",
      "\n",
      "People's Education Society University Ring Road Campus (PESU RR or just PESU), formerly PES Institute of Technology (PESIT), is one of three private universities under the name PES University in Bengaluru, India.\n",
      "\n",
      "QUESTION: What is CORI\n",
      "Crucible Of Research and Innovation (CORI) is a multi-disciplinary research center at PES University.\n",
      "and generates 13 watts power with S-band RF communication.\n",
      "[9]\n",
      "\n",
      "Centre for Intelligent Systems (CIS) is a research center at PES University which researches on topics like Control Systems, Speech, Image and Signal Processing, Robotics, Artificial intelligence and Low Power VLSI design.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question = [\"What is PES\", \"Where is PES located\", \"How to get admission in PES\", \"What is CORI\"]\n",
    "\n",
    "for j in question:\n",
    "  que=sent_tokenize(j)\n",
    "  sentences=sent_tokenize(s)\n",
    "  #q contains a list of cleaned sentence tokens of question\n",
    "  q=get_cleaned_sentences(que,stopwords=True)\n",
    "  #preprocessed contains a list of cleaned sentence tokens of the reference text\n",
    "  preprocessed=get_cleaned_sentences(sentences,stopwords=True)\n",
    "  \n",
    "  preprocessed.append(q[0])\n",
    "  i=len(preprocessed)-1\n",
    "  print(\"QUESTION:\",j)\n",
    "  \n",
    "  tfidf_vect=TfidfVectorizer()\n",
    "  df=create_document_term_matrix(preprocessed,tfidf_vect) \n",
    "  df_list = df.values.tolist()\n",
    "  answertype(j)\n",
    "  print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPYpmwI+WLAMU67ObaaLsws",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "QA- System",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
